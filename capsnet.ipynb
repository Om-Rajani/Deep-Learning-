{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ompra\\anaconda3\\envs\\capsule_net\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "USE_CUDA = True if torch.cuda.is_available() else False\n",
    "\n",
    "print('CUDA available:', USE_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONVOLUTIONAL LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=256, kernel_size=9):\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=kernel_size,\n",
    "                              stride=1\n",
    "                              )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.conv(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRIMARY CAPSULE LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=8, in_channels=256, out_channels=32, kernel_size=9, num_routes=32 * 6 * 6):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.num_routes = num_routes\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=0)\n",
    "            for _ in range(num_capsules)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = [capsule(x) for capsule in self.capsules]\n",
    "        u = torch.stack(u, dim=1)\n",
    "        u = u.view(x.size(0), self.num_routes, -1)\n",
    "        return self.squash(u)\n",
    "\n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm * input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIGIT CAPSULE LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCaps(nn.Module):\n",
    "    def __init__(self, num_capsules=10, num_routes=32 * 6 * 6, in_channels=8, out_channels=16):\n",
    "        super(DigitCaps, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_routes = num_routes\n",
    "        self.num_capsules = num_capsules\n",
    "\n",
    "        self.W = nn.Parameter(torch.randn(1, num_routes, num_capsules, out_channels, in_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4)\n",
    "\n",
    "        W = torch.cat([self.W] * batch_size, dim=0)\n",
    "        u_hat = torch.matmul(W, x)\n",
    "\n",
    "        b_ij = Variable(torch.zeros(1, self.num_routes, self.num_capsules, 1))\n",
    "        if USE_CUDA:\n",
    "            b_ij = b_ij.cuda()\n",
    "\n",
    "        num_iterations = 3\n",
    "        for iteration in range(num_iterations):\n",
    "            c_ij = F.softmax(b_ij, dim=1)\n",
    "            c_ij = torch.cat([c_ij] * batch_size, dim=0).unsqueeze(4)\n",
    "\n",
    "            s_j = (c_ij * u_hat).sum(dim=1, keepdim=True)\n",
    "            v_j = self.squash(s_j)\n",
    "\n",
    "            if iteration < num_iterations - 1:\n",
    "                a_ij = torch.matmul(u_hat.transpose(3, 4), torch.cat([v_j] * self.num_routes, dim=1))\n",
    "                b_ij = b_ij + a_ij.squeeze(4).mean(dim=0, keepdim=True)\n",
    "\n",
    "        return v_j.squeeze(1)\n",
    "\n",
    "    def squash(self, input_tensor):\n",
    "        squared_norm = (input_tensor ** 2).sum(-1, keepdim=True)\n",
    "        output_tensor = squared_norm * input_tensor / ((1. + squared_norm) * torch.sqrt(squared_norm))\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_width=28, input_height=28, input_channel=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.input_channel = input_channel\n",
    "        self.reconstraction_layers = nn.Sequential(\n",
    "            nn.Linear(16 * 10, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, self.input_height * self.input_width * self.input_channel),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, data):\n",
    "        classes = torch.sqrt((x ** 2).sum(2))\n",
    "        classes = F.softmax(classes, dim=0)\n",
    "\n",
    "        _, max_length_indices = classes.max(dim=1)\n",
    "        masked = Variable(torch.sparse.torch.eye(10))\n",
    "        if USE_CUDA:\n",
    "            masked = masked.cuda()\n",
    "        masked = masked.index_select(dim=0, index=Variable(max_length_indices.squeeze(1).data))\n",
    "        t = (x * masked[:, :, None, None]).view(x.size(0), -1)\n",
    "        reconstructions = self.reconstraction_layers(t)\n",
    "        reconstructions = reconstructions.view(-1, self.input_channel, self.input_width, self.input_height)\n",
    "        return reconstructions, masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAPSNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    def __init__(self, config=None):\n",
    "        super(CapsNet, self).__init__()\n",
    "        if config:\n",
    "            self.conv_layer = ConvLayer(config.cnn_in_channels, config.cnn_out_channels, config.cnn_kernel_size)\n",
    "            self.primary_capsules = PrimaryCaps(config.pc_num_capsules, config.pc_in_channels, config.pc_out_channels,\n",
    "                                                config.pc_kernel_size, config.pc_num_routes)\n",
    "            self.digit_capsules = DigitCaps(config.dc_num_capsules, config.dc_num_routes, config.dc_in_channels,\n",
    "                                            config.dc_out_channels)\n",
    "            self.decoder = Decoder(config.input_width, config.input_height, config.cnn_in_channels)\n",
    "        else:\n",
    "            self.conv_layer = ConvLayer()\n",
    "            self.primary_capsules = PrimaryCaps()\n",
    "            self.digit_capsules = DigitCaps()\n",
    "            self.decoder = Decoder()\n",
    "\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, data):\n",
    "        output = self.digit_capsules(self.primary_capsules(self.conv_layer(data)))\n",
    "        reconstructions, masked = self.decoder(output, data)\n",
    "        return output, reconstructions, masked\n",
    "\n",
    "    def loss(self, data, x, target, reconstructions):\n",
    "        return self.margin_loss(x, target) + self.reconstruction_loss(data, reconstructions)\n",
    "\n",
    "    def margin_loss(self, x, labels, size_average=True):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        v_c = torch.sqrt((x ** 2).sum(dim=2, keepdim=True))\n",
    "\n",
    "        left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
    "        right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
    "\n",
    "        loss = labels * left + 0.5 * (1.0 - labels) * right\n",
    "        loss = loss.sum(dim=1).mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def reconstruction_loss(self, data, reconstructions):\n",
    "        loss = self.mse_loss(reconstructions.view(reconstructions.size(0), -1), data.view(reconstructions.size(0), -1))\n",
    "        return loss * 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, dataset, _batch_size):\n",
    "        super(Dataset, self).__init__()\n",
    "        if dataset == 'mnist':\n",
    "            dataset_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ])\n",
    "\n",
    "            train_dataset = datasets.MNIST('/data/mnist', train=True, download=True,\n",
    "                                           transform=dataset_transform)\n",
    "            test_dataset = datasets.MNIST('/data/mnist', train=False, download=True,\n",
    "                                          transform=dataset_transform)\n",
    "\n",
    "            self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=_batch_size, shuffle=True)\n",
    "            self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=_batch_size, shuffle=False)\n",
    "\n",
    "        elif dataset == 'cifar10':\n",
    "            data_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "            train_dataset = datasets.CIFAR10(\n",
    "                '/data/cifar', train=True, download=True, transform=data_transform)\n",
    "            test_dataset = datasets.CIFAR10(\n",
    "                '/data/cifar', train=False, download=True, transform=data_transform)\n",
    "\n",
    "            self.train_loader = torch.utils.data.DataLoader(\n",
    "                train_dataset, batch_size=_batch_size, shuffle=True)\n",
    "\n",
    "            self.test_loader = torch.utils.data.DataLoader(\n",
    "                test_dataset, batch_size=_batch_size, shuffle=False)\n",
    "        elif dataset == 'office-caltech':\n",
    "            pass\n",
    "        elif dataset == 'office31':\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING THE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE_CUDA: True\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:03, 3035840.91it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz to /data/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 29410637.92it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/mnist\\MNIST\\raw\\train-labels-idx1-ubyte.gz to /data/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1649664it [00:00, 3829774.50it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/mnist\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to /data/mnist\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, ?it/s]                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/mnist\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to /data/mnist\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/600 [00:00<04:56,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Batch: [1/600], train accuracy: 0.050000, loss: 0.008995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 101/600 [00:26<02:12,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Batch: [101/600], train accuracy: 0.930000, loss: 0.004104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 201/600 [00:53<01:47,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Batch: [201/600], train accuracy: 0.970000, loss: 0.002332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 301/600 [01:21<01:24,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Batch: [301/600], train accuracy: 0.960000, loss: 0.001182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 401/600 [01:50<00:58,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Batch: [401/600], train accuracy: 0.980000, loss: 0.000704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 501/600 [02:20<00:28,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Batch: [501/600], train accuracy: 0.940000, loss: 0.000873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:49<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], train loss: 0.002122\n",
      "Epoch: [1/1], test accuracy: 0.982500, loss: 0.059379\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "#from capsnet import CapsNet\n",
    "#from data_loader import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "USE_CUDA = True if torch.cuda.is_available() else False\n",
    "print('USE_CUDA:', USE_CUDA)\n",
    "BATCH_SIZE = 100\n",
    "N_EPOCHS = 1\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "'''\n",
    "Config class to determine the parameters for capsule net\n",
    "'''\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        if dataset == 'mnist':\n",
    "            # CNN (cnn)\n",
    "            self.cnn_in_channels = 1\n",
    "            self.cnn_out_channels = 256\n",
    "            self.cnn_kernel_size = 9\n",
    "\n",
    "            # Primary Capsule (pc)\n",
    "            self.pc_num_capsules = 8\n",
    "            self.pc_in_channels = 256\n",
    "            self.pc_out_channels = 32\n",
    "            self.pc_kernel_size = 9\n",
    "            self.pc_num_routes = 32 * 6 * 6\n",
    "\n",
    "            # Digit Capsule (dc)\n",
    "            self.dc_num_capsules = 10\n",
    "            self.dc_num_routes = 32 * 6 * 6\n",
    "            self.dc_in_channels = 8\n",
    "            self.dc_out_channels = 16\n",
    "\n",
    "            # Decoder\n",
    "            self.input_width = 28\n",
    "            self.input_height = 28\n",
    "\n",
    "        elif dataset == 'cifar10':\n",
    "            # CNN (cnn)\n",
    "            self.cnn_in_channels = 3\n",
    "            self.cnn_out_channels = 256\n",
    "            self.cnn_kernel_size = 9\n",
    "\n",
    "            # Primary Capsule (pc)\n",
    "            self.pc_num_capsules = 8\n",
    "            self.pc_in_channels = 256\n",
    "            self.pc_out_channels = 32\n",
    "            self.pc_kernel_size = 9\n",
    "            self.pc_num_routes = 32 * 8 * 8\n",
    "\n",
    "            # Digit Capsule (dc)\n",
    "            self.dc_num_capsules = 10\n",
    "            self.dc_num_routes = 32 * 8 * 8\n",
    "            self.dc_in_channels = 8\n",
    "            self.dc_out_channels = 16\n",
    "\n",
    "            # Decoder\n",
    "            self.input_width = 32\n",
    "            self.input_height = 32\n",
    "\n",
    "        elif dataset == 'your own dataset':\n",
    "            pass\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_loader, epoch):\n",
    "    capsule_net = model\n",
    "    capsule_net.train()\n",
    "    n_batch = len(list(enumerate(train_loader)))\n",
    "    total_loss = 0\n",
    "    for batch_id, (data, target) in enumerate(tqdm(train_loader)):\n",
    "\n",
    "        target = torch.sparse.torch.eye(10).index_select(dim=0, index=target)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        if USE_CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output, reconstructions, masked = capsule_net(data)\n",
    "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct = sum(np.argmax(masked.data.cpu().numpy(), 1) == np.argmax(target.data.cpu().numpy(), 1))\n",
    "        train_loss = loss.item()\n",
    "        total_loss += train_loss\n",
    "        if batch_id % 100 == 0:\n",
    "            tqdm.write(\"Epoch: [{}/{}], Batch: [{}/{}], train accuracy: {:.6f}, loss: {:.6f}\".format(\n",
    "                epoch,\n",
    "                N_EPOCHS,\n",
    "                batch_id + 1,\n",
    "                n_batch,\n",
    "                correct / float(BATCH_SIZE),\n",
    "                train_loss / float(BATCH_SIZE)\n",
    "                ))\n",
    "    tqdm.write('Epoch: [{}/{}], train loss: {:.6f}'.format(epoch,N_EPOCHS,total_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(capsule_net, test_loader, epoch):\n",
    "    capsule_net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for batch_id, (data, target) in enumerate(test_loader):\n",
    "\n",
    "        target = torch.sparse.torch.eye(10).index_select(dim=0, index=target)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        if USE_CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output, reconstructions, masked = capsule_net(data)\n",
    "        loss = capsule_net.loss(data, output, target, reconstructions)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        correct += sum(np.argmax(masked.data.cpu().numpy(), 1) ==\n",
    "                       np.argmax(target.data.cpu().numpy(), 1))\n",
    "\n",
    "    tqdm.write(\n",
    "        \"Epoch: [{}/{}], test accuracy: {:.6f}, loss: {:.6f}\".format(epoch, N_EPOCHS, correct / len(test_loader.dataset),\n",
    "                                                                  test_loss / len(test_loader)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(1)\n",
    "    # dataset = 'cifar10'\n",
    "    dataset = 'mnist'\n",
    "    config = Config(dataset)\n",
    "    mnist = Dataset(dataset, BATCH_SIZE)\n",
    "\n",
    "    capsule_net = CapsNet(config)\n",
    "    capsule_net = torch.nn.DataParallel(capsule_net)\n",
    "    if USE_CUDA:\n",
    "        capsule_net = capsule_net.cuda()\n",
    "    capsule_net = capsule_net.module\n",
    "\n",
    "    optimizer = torch.optim.Adam(capsule_net.parameters())\n",
    "\n",
    "    for e in range(1, N_EPOCHS + 1):\n",
    "        train(capsule_net, optimizer, mnist.train_loader, e)\n",
    "        test(capsule_net, mnist.test_loader, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f1628575b2ecc8a8015971973d741040dea751eccad6223a7a8391c7f435442"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('capsule_net')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
